{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **05 - MLModelEvaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Train a machine learning regression model to predict the sale price of inherited houses and other properties in the region.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/cleaned/HousePricesCleaned.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* docs/plots/regression_performance.png\n",
        "* outputs/ml_pipeline/predict_price/v1/X_train.csv\n",
        "* outputs/ml_pipeline/predict_price/v1/y_train.csv\n",
        "* outputs/ml_pipeline/predict_price/v1/X_test.csv\n",
        "* outputs/ml_pipeline/predict_price/v1/y_test.csv\n",
        "* outputs/ml_pipeline/predict_price/v1/regression_pipeline.pkl\n",
        "* outputs/ml_pipeline/predict_price/v1/features_importance.png\n",
        "* docs/plots/features_importance.png\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* This notebook deals with Business Requirement 2: Regression Analysis for Price Prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Imports the Numpy and Pandas library and reads CSV file HousePricesRecords.csv into DataFrame df and displays the first 10 rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"outputs/datasets/collection/HousePricesRecords.csv\")\n",
        "\n",
        "print(df.shape)\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Imports libraries for building a machine learning regression pipeline, incorporating feature engineering, preprocessing, and modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from feature_engine.imputation import MeanMedianImputer\n",
        "from feature_engine.selection import DropFeatures\n",
        "from feature_engine.imputation import CategoricalImputer\n",
        "\n",
        "from feature_engine import creation\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "from feature_engine.selection import SmartCorrelatedSelection\n",
        "from feature_engine import transformation as vt\n",
        "from feature_engine.outliers import Winsorizer\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Drops irrelevant features using DropFeatures, imputes missing values using MeanMedianImputer, encodes categorical variables with OrdinalEncoder, applies log and power transformations using LogTransformer and PowerTransformer, handles outliers with Winsorizer, removes highly correlated features using SmartCorrelatedSelection, standardizes data with StandardScaler, selects important features using SelectFromModel, and trains the specified machine learning model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def PipelineOptimization(model):\n",
        "  pipeline_base = Pipeline([\n",
        "     ( 'drop',  DropFeatures(features_to_drop=['EnclosedPorch', 'WoodDeckSF', 'GarageFinish', 'BsmtFinType1', 'BsmtExposure', 'GarageYrBlt'])),\n",
        "\n",
        "     ( 'mean',  MeanMedianImputer(imputation_method='mean',\n",
        "                                     variables=['LotFrontage', 'BedroomAbvGr']) ),\n",
        "\n",
        "     ( 'median',  MeanMedianImputer(imputation_method='median',\n",
        "                                     variables=['2ndFlrSF', 'MasVnrArea']) ),\n",
        "   \n",
        "    (\"OrdinalCategoricalEncoder\",OrdinalEncoder(encoding_method='arbitrary', \n",
        "                                                  variables = ['KitchenQual'])),\n",
        "    \n",
        "    ('lt', vt.LogTransformer(variables = ['GrLivArea', 'LotArea', 'LotFrontage']) ),\n",
        "\n",
        "    ('pt', vt.PowerTransformer(variables = ['GarageArea', 'MasVnrArea', 'OpenPorchSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF']) ),\n",
        "       \n",
        "      \n",
        "    (\"Winsoriser_iqr\",Winsorizer(capping_method='iqr', fold=1.5, tail='both', \n",
        "                                                  variables=['1stFlrSF',\n",
        "                                                             '2ndFlrSF',\n",
        "                                                             'GarageArea',\n",
        "                                                             'LotArea',\n",
        "                                                             'LotFrontage',\n",
        "                                                             'MasVnrArea',\n",
        "                                                             'OpenPorchSF',\n",
        "                                                             'TotalBsmtSF',\n",
        "                                                      ])),      \n",
        "       \n",
        "    (\"SmartCorrelatedSelection\",SmartCorrelatedSelection(variables= None,\n",
        "       method=\"spearman\", threshold=0.8,selection_method=\"variance\") ),\n",
        "\n",
        "    (\"feat_scaling\", StandardScaler() ),\n",
        "\n",
        "    (\"feat_selection\",  SelectFromModel(model) ),\n",
        "\n",
        "    (\"model\", model ),\n",
        "    ])\n",
        "\n",
        "  return pipeline_base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defines HyperparameterOptimizationSearch for performing hyperparameter tuning using GridSearchCV. Initializes with models, hyperparameter grids, and a dictionary to store grid search results. Implements fit to iterate over models, apply PipelineOptimization, and run GridSearchCV with cross-validation, parallel processing, and optional scoring. Stores fitted grid searches in self.grid_searches. Defines score_summary to compile results by extracting cross-validation scores, computing statistics (min, max, mean, std), and formatting results into a sorted DataFrame. Returns the summary DataFrame and grid search results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "class HyperparameterOptimizationSearch:\n",
        "\n",
        "    def __init__(self, models, params):\n",
        "        self.models = models\n",
        "        self.params = params\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "\n",
        "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
        "        for key in self.keys:\n",
        "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
        "            model=  PipelineOptimization(self.models[key])\n",
        "\n",
        "            params = self.params[key]\n",
        "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs, verbose=verbose, scoring=scoring)\n",
        "            gs.fit(X,y)\n",
        "            self.grid_searches[key] = gs    \n",
        "\n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, params):\n",
        "            d = {\n",
        "                 'estimator': key,\n",
        "                 'min_score': min(scores),\n",
        "                 'max_score': max(scores),\n",
        "                 'mean_score': np.mean(scores),\n",
        "                 'std_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**params,**d})\n",
        "\n",
        "        rows = []\n",
        "        for k in self.grid_searches:\n",
        "            params = self.grid_searches[k].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[k].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                r = self.grid_searches[k].cv_results_[key]        \n",
        "                scores.append(r.reshape(len(params),1))\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(params,all_scores):\n",
        "                rows.append((row(k, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "\n",
        "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
        "        columns = columns + [c for c in df.columns if c not in columns]\n",
        "\n",
        "        return df[columns], self.grid_searches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Splits the dataset into training and testing sets, with 20% of the data for testing, using train_test_split. The target variable SalePrice is separated from the features. Prints the column names and shapes of the training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop(['SalePrice'], axis=1),\n",
        "    df['SalePrice'],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Columns in X_train:\", X_train.columns)\n",
        "print(\"Columns in X_test:\", X_test.columns)\n",
        "\n",
        "print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\",  X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Displays the first 10 rows of both the training set (X_train) and the testing set (X_test) by using the head() function. Preview the data in both sets to verify the feature separation and ensure the split is correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(X_train.head(10))\n",
        "print(X_test.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defines two dictionaries: models_quick_search, which includes seven regression models (LinearRegression, DecisionTreeRegressor, RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor, and XGBRegressor), and params_quick_search, which specifies hyperparameter grids for each model, including options for parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_quick_search = {\n",
        "    \"LinearRegression\": LinearRegression(),\n",
        "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=42),\n",
        "    \"RandomForestRegressor\": RandomForestRegressor(random_state=42),\n",
        "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=42),\n",
        "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=42),\n",
        "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=42),\n",
        "    \"XGBRegressor\": XGBRegressor(random_state=42),\n",
        "}\n",
        "\n",
        "params_quick_search = {\n",
        "    \"LinearRegression\": {},\n",
        "\n",
        "    \"DecisionTreeRegressor\": {\n",
        "        'model__max_depth': [None, 4, 15],\n",
        "        'model__min_samples_split': [2, 50],\n",
        "        'model__min_samples_leaf': [1, 50],\n",
        "        'model__max_leaf_nodes': [None, 50],\n",
        "    },\n",
        "\n",
        "    \"RandomForestRegressor\": {\n",
        "        'model__n_estimators': [100, 50, 140],\n",
        "        'model__max_depth': [None, 4, 15],\n",
        "        'model__min_samples_split': [2, 50],\n",
        "        'model__min_samples_leaf': [1, 50],\n",
        "        'model__max_leaf_nodes': [None, 50],\n",
        "    },\n",
        "\n",
        "    \"ExtraTreesRegressor\": {\n",
        "        'model__n_estimators': [100, 50, 150],\n",
        "        'model__max_depth': [None, 3, 15],\n",
        "        'model__min_samples_split': [2, 50],\n",
        "        'model__min_samples_leaf': [1, 50],\n",
        "    },\n",
        "\n",
        "    \"AdaBoostRegressor\": {\n",
        "        'model__n_estimators': [50, 25, 80, 150],\n",
        "        'model__learning_rate': [1, 0.1, 2],\n",
        "        'model__loss': ['linear', 'square', 'exponential'],\n",
        "    },\n",
        "\n",
        "    \"GradientBoostingRegressor\": {\n",
        "        'model__n_estimators': [100, 50, 140],\n",
        "        'model__learning_rate': [0.1, 0.01, 0.001],\n",
        "        'model__max_depth': [3, 15, None],\n",
        "        'model__min_samples_split': [2, 50],\n",
        "        'model__min_samples_leaf': [1, 50],\n",
        "        'model__max_leaf_nodes': [None, 50],\n",
        "    },\n",
        "\n",
        "    \"XGBRegressor\": {\n",
        "        'model__n_estimators': [30, 80, 200],\n",
        "        'model__max_depth': [None, 3, 15],\n",
        "        'model__learning_rate': [0.01, 0.1, 0.001],\n",
        "        'model__gamma': [0, 0.1],\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Imports the warnings module and suppresses all warnings. Initializes an instance of the HyperparameterOptimizationSearch class with the models_quick_search and params_quick_search dictionaries, which contain the models and their hyperparameter grids. The fit method of HyperparameterOptimizationSearch is called to perform grid search with cross-validation (cv=5) on the training data (X_train and y_train). It uses the R-squared (r2) metric for scoring, runs the search in parallel using all available CPU cores (n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
        "\n",
        "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
        "search.fit(X_train, y_train, scoring='r2', n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calls the score_summary method from the HyperparameterOptimizationSearch class, passing sort_by='mean_score' to sort the summary DataFrame by the mean score (average performance across cross-validation folds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defines two dictionaries for performing a hyperparameter search with the ExtraTreesRegressor model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_search = {\n",
        "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=42),\n",
        "}\n",
        "\n",
        "params_search = {\n",
        "    \"ExtraTreesRegressor\":{'model__n_estimators': [50,100,150],\n",
        "        'model__max_depth': [None, 3, 15],\n",
        "        'model__min_samples_split': [2, 50],\n",
        "        'model__min_samples_leaf': [1,50],\n",
        "        },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " Performs hyperparameter optimization using the HyperparameterOptimizationSearch method. It searches for the best model and hyperparameters from models_search and params_search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
        "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calls the score_summary method from the HyperparameterOptimizationSearch class, passing sort_by='mean_score' to sort the summary DataFrame by the mean score (average performance across cross-validation folds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Selects the best-performing model from the grid_search_summary by accessing the first row and first column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = grid_search_summary.iloc[0,0]\n",
        "best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Retrieves the best hyperparameters for the model selected through grid search. Acesses the best_params_ attribute of the best model from the grid_search_pipelines dictionary, which contains the tuned parameters that produced the optimal model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_parameters = grid_search_pipelines[best_model].best_params_\n",
        "best_parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Retrieves the best estimator from the grid search that achieved the best performance during the grid search process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
        "best_regressor_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Performs feature importance analysis on a regression pipeline. Selects the preprocessing steps from the pipeline, applies them to transform the training data, and extracts the transformed feature names. Identifies selected features if feature selection is applied. Retrieves feature importances if supported by the model, then sorts and displays the most important features. If feature importance is available, it plots a bar chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "sns.set_theme(style='whitegrid')\n",
        "\n",
        "data_cleaning_feat_eng_steps = 9\n",
        "\n",
        "pipeline_steps = best_regressor_pipeline.steps[:data_cleaning_feat_eng_steps]\n",
        "temp_pipeline = Pipeline(pipeline_steps)\n",
        "\n",
        "transformed_data = temp_pipeline.fit_transform(X_train)\n",
        "\n",
        "def get_feature_names_from_pipeline(pipeline_steps, X_train):\n",
        "    feature_names = X_train.columns  # Default to original feature names\n",
        "    \n",
        "    for name, transformer in pipeline_steps:\n",
        "        if hasattr(transformer, 'get_feature_names_out'):\n",
        "            feature_names = transformer.get_feature_names_out()\n",
        "    \n",
        "    return feature_names\n",
        "\n",
        "feature_names = get_feature_names_from_pipeline(best_regressor_pipeline.steps[:data_cleaning_feat_eng_steps], X_train)\n",
        "\n",
        "transformed_data = pd.DataFrame(transformed_data, columns=feature_names)\n",
        "\n",
        "if 'feat_selection' in best_regressor_pipeline.named_steps:\n",
        "    feat_selector = best_regressor_pipeline['feat_selection']\n",
        "    selected_columns = transformed_data.columns[feat_selector.get_support()]\n",
        "else:\n",
        "    selected_columns = transformed_data.columns\n",
        "\n",
        "if hasattr(best_regressor_pipeline['model'], 'feature_importances_'):\n",
        "    feature_importances = best_regressor_pipeline['model'].feature_importances_\n",
        "else:\n",
        "    print(\"Model does not have feature importances attribute. Skipping this step.\")\n",
        "    feature_importances = None\n",
        "\n",
        "if feature_importances is not None:\n",
        "    df_feature_importance = pd.DataFrame({\n",
        "        'Feature': selected_columns,\n",
        "        'Importance': feature_importances\n",
        "    }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    print(f\"* These are the {len(df_feature_importance)} most important features in descending order: \\n{df_feature_importance['Feature'].to_list()}\")\n",
        "\n",
        "    df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No feature importance available to plot.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluates performance of a regression model by calculating and visualizing key metrics. regression_performance function evaluates model on both training and test sets, calling regression_evaluation to compute R² score, mean absolute error, mean squared error, and root mean squared error for each dataset. regression_evaluation_plots function generates scatter plots comparing actual values to predicted values for both training and test sets, overlaying a red line representing perfect predictions. Plots are saved as an image and displayed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error \n",
        "import numpy as np\n",
        "\n",
        "def regression_performance(X_train, y_train, X_test, y_test,pipeline):\n",
        "\tprint(\"Model Evaluation \\n\")\n",
        "\tprint(\"* Train Set\")\n",
        "\tregression_evaluation(X_train,y_train,pipeline)\n",
        "\tprint(\"* Test Set\")\n",
        "\tregression_evaluation(X_test,y_test,pipeline)\n",
        "\n",
        "def regression_evaluation(X, y, pipeline):\n",
        "  prediction = pipeline.predict(X)\n",
        "  print('R2 Score:', round(r2_score(y, prediction), 3))\n",
        "  print('Mean Absolute Error:', round(mean_absolute_error(y, prediction), 3))\n",
        "  print('Mean Squared Error:', round(mean_squared_error(y, prediction), 3))\n",
        "  print('Root Mean Squared Error:', round(np.sqrt(mean_squared_error(y, prediction)), 3))\n",
        "  print(\"\\n\")\n",
        "\n",
        "\n",
        "def regression_evaluation_plots(X_train, y_train, X_test, y_test,pipeline, alpha_scatter=0.5):\n",
        "  pred_train = pipeline.predict(X_train)\n",
        "  pred_test = pipeline.predict(X_test)\n",
        "\n",
        "\n",
        "  fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,6))\n",
        "  sns.scatterplot(x=y_train, y=pred_train, alpha=alpha_scatter, ax=axes[0])\n",
        "  sns.lineplot(x=y_train , y=y_train, color='red', ax=axes[0])\n",
        "  axes[0].set_xlabel(\"Actual\")\n",
        "  axes[0].set_ylabel(\"Predictions\")\n",
        "  axes[0].set_title(\"Train Set\")\n",
        "\n",
        "  sns.scatterplot(x=y_test, y=pred_test, alpha=alpha_scatter, ax=axes[1])\n",
        "  sns.lineplot(x=y_test, y=y_test, color='red', ax=axes[1])\n",
        "  axes[1].set_xlabel(\"Actual\")\n",
        "  axes[1].set_ylabel(\"Predictions\")\n",
        "  axes[1].set_title(\"Test Set\")\n",
        "  plt.savefig(f'docs/plots/regression_performance.png', bbox_inches='tight')  \n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluates performance of the best regressor pipeline on both training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "regression_performance(X_train, y_train, X_test, y_test,best_regressor_pipeline)\n",
        "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pipeline of the best regressor model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_regressor_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creates a machine learning pipeline for regression that imputes missing values in the TotalBsmtSF feature with the mean, applies a log transformation to GrLivArea, a power transformation to TotalBsmtSF, the IQR method to cap extreme values in TotalBsmtSF and GarageArea, feature scaling with StandardScaler, and applies an ExtraTreesRegressor with hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def PipelineOptimization(model):\n",
        "    pipeline_base = Pipeline(steps=[  \n",
        "    ( 'mean',  MeanMedianImputer(imputation_method='mean',\n",
        "                                     variables=['TotalBsmtSF']) ),\n",
        "                                     \n",
        "    ('lt', vt.LogTransformer(variables = ['GrLivArea']) ),\n",
        "\n",
        "    ('pt', vt.PowerTransformer(variables = ['TotalBsmtSF']) ),\n",
        "      \n",
        "    (\"Winsoriser_iqr\",Winsorizer(capping_method='iqr', fold=1.5, tail='both', \n",
        "                                                  variables=['TotalBsmtSF', 'GarageArea']) ),      \n",
        "\n",
        "    (\"feat_scaling\", StandardScaler() ),\n",
        "\n",
        "  ('model', ExtraTreesRegressor(max_depth=15, min_samples_split=50,\n",
        "                                     n_estimators=150, random_state=42))])        \n",
        "    return pipeline_base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prints original column names in the df dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Original columns in the dataset:\", df.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checks if columns in best_features are present in both X_train and X_test datasets. Identifies and prints any missing columns. If no columns are missing, filters both datasets to include only best_features and prints shapes and first 5 rows of X_train. Prints a message if any columns are missing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_features = ['OverallQual', 'GrLivArea', 'GarageArea', 'YearBuilt', 'TotalBsmtSF']\n",
        "\n",
        "missing_train_columns = [col for col in best_features if col not in X_train.columns]\n",
        "missing_test_columns = [col for col in best_features if col not in X_test.columns]\n",
        "\n",
        "if missing_train_columns:\n",
        "    print(f\"Missing columns in X_train: {missing_train_columns}\")\n",
        "\n",
        "if missing_test_columns:\n",
        "    print(f\"Missing columns in X_test: {missing_test_columns}\")\n",
        "\n",
        "if not missing_train_columns and not missing_test_columns:\n",
        "    X_train = X_train[best_features]\n",
        "    X_test = X_test[best_features]\n",
        "\n",
        "    print(\"* Train set:\", X_train.shape, y_train.shape, \"\\n* Test set:\", X_test.shape, y_test.shape)\n",
        "    print(X_train.head(5))\n",
        "else:\n",
        "    print(\"Some columns are missing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dictionary containing a model selection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dictionary containing a parameter selection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defines a set of hyperparameters for tuning an ExtraTreesRegressor model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "params_search = {\n",
        "    \"ExtraTreesRegressor\": {\n",
        "        'model__n_estimators': [50, 100, 150],\n",
        "        'model__max_depth': [3, 5, 10],\n",
        "        'model__min_samples_split': [5, 10, 20],\n",
        "        'model__min_samples_leaf': [5, 10, 20],\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Performs hyperparameter optimization using HyperparameterOptimizationSearch with models (models_search) and hyperparameters (params_search). Fit method trains the model on X_train and y_train with 5-fold cross-validation (cv=5), evaluating performance using R² scoring (scoring='r2'). Utilizes all available CPU cores (n_jobs=-1) for parallel computation, aiming to find the best hyperparameter combination for ExtraTreesRegressor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
        "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Retrieves a summary of the grid search results using the score_summary method from the search object, sorting the results by the mean score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Selects best model from grid_search_summary DataFrame by accessing the first row and first column, which corresponds to the model with the highest mean score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = grid_search_summary.iloc[0,0]\n",
        "best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Retrieves the best regressor pipeline from grid_search_pipelines using the best model identifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_pipeline_regressor = grid_search_pipelines[best_model].best_estimator_\n",
        "best_pipeline_regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Attempts to create a directory structure for saving a machine learning pipeline, defining a path (file_path) for version 'v1' under outputs/ml_pipeline/predict_price/. Uses os.makedirs to create the directory and prints any exception messages if an error occurs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "import os\n",
        "\n",
        "version = 'v1'\n",
        "file_path = f'outputs/ml_pipeline/predict_price/{version}'\n",
        "\n",
        "try:\n",
        "  os.makedirs(name=file_path)\n",
        "except Exception as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Displays the first 10 rows of the X_train dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saves the X_train and y_train datasets as CSV files in the specified directory (file_path). The X_train data is saved as X_train.csv and the y_train data as y_train.csv, both without including row indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train.to_csv(f\"{file_path}/X_train.csv\", index=False)\n",
        "y_train.to_csv(f\"{file_path}/y_train.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Displays the first 10 rows of the y_test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saves the X_test and y_test datasets as CSV files in the specified directory (file_path). The X_test data is saved as X_test.csv and the y_test data as y_test.csv, both without including row indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test.to_csv(f\"{file_path}/X_test.csv\", index=False) \n",
        "y_test.to_csv(f\"{file_path}/y_test.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show the steps within the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_pipeline_regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prints the machine learning pipeline preprocessing and modeling steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(best_pipeline_regressor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saves best_pipeline_regressor to a file using joblib. It serializes the pipeline object and stores it as regression_pipeline.pkl in a directory defined by file_path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "joblib.dump(value=best_pipeline_regressor, filename=f\"{file_path}/regression_pipeline.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creates a bar plot to visualize the feature importance of a machine learning model using the data stored in df_feature_importance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creates a bar plot for feature importance and saves it as images in two specified locations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_feature_importance.plot(kind='bar',x='Feature',y='Importance')\n",
        "plt.savefig(f'{file_path}/features_importance.png', bbox_inches='tight')\n",
        "plt.savefig(f'docs/plots/features_importance.png', bbox_inches='tight') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prints the machine learning pipeline preprocessing and modeling steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(best_pipeline_regressor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusions and Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The regression pipeline is now complete.\n",
        "\n",
        "The Next steps are to deploy it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "3.12.1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
