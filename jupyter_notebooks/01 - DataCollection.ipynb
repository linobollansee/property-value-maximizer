{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **01 - DataCollection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Fetch data from Kaggle and store it as raw data in inputs/datasets/raw\n",
        "* Inspect data fetched via Kaggle\n",
        "* Save data fetched under outputs/datasets/collection/\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* My personal Kaggle JSON file to authenticate with Kaggle \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* inputs/datasets/raw/house-price-20211124T154130Z-001/house-price/house_prices_records.csv\n",
        "* inputs/datasets/raw/house-price-20211124T154130Z-001/house-price/inherited_houses.csv\n",
        "* inputs/datasets/raw/house-metadata.txt\n",
        "* outputs/datasets/collection/HousePricesRecords.csv\n",
        "* outputs/datasets/collection/InheritedHouses.csv\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* The file inherited_houses.csv contains features and target variables for the business objective, serving as the foundation for the ML model. It also includes house features for which the client seeks individual and total price predictions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspaces/property-value-maximizer/jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspaces/property-value-maximizer'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Download data from Kaggle\n",
        "\n",
        "The Kaggle API was used to fetch the raw project data, requiring the installation of the Kaggle package.\n",
        "\n",
        "To authenticate, the API requires a token stored in a kaggle.json file. The token was obtained as follows:\n",
        "\n",
        "Log into your Kaggle account.\n",
        "Go to Settings via the user profile menu.\n",
        "Locate the API section.\n",
        "Click Expire API Token to remove any existing tokens.\n",
        "Click Create New API Token to generate a new one.\n",
        "Download the kaggle.json file.\n",
        "Move kaggle.json to the project's root directory without renaming or changing its extension.\n",
        "This ensures proper authentication for accessing Kaggle data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle==1.5.12 in /home/cistudent/.local/lib/python3.12/site-packages (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in /home/cistudent/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from kaggle==1.5.12) (1.17.0)\n",
            "Requirement already satisfied: certifi in /home/cistudent/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from kaggle==1.5.12) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil in /home/cistudent/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from kaggle==1.5.12) (2.9.0.post0)\n",
            "Requirement already satisfied: requests in /home/cistudent/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from kaggle==1.5.12) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /home/cistudent/.local/lib/python3.12/site-packages (from kaggle==1.5.12) (4.67.1)\n",
            "Requirement already satisfied: python-slugify in /home/cistudent/.local/lib/python3.12/site-packages (from kaggle==1.5.12) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /home/cistudent/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from kaggle==1.5.12) (2.2.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /home/cistudent/.local/lib/python3.12/site-packages (from python-slugify->kaggle==1.5.12) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/cistudent/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from requests->kaggle==1.5.12) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/cistudent/.pyenv/versions/3.12.1/lib/python3.12/site-packages (from requests->kaggle==1.5.12) (3.10)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install kaggle==1.5.12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This code configures Kaggle API authentication by setting the KAGGLE_CONFIG_DIR environment variable to the current working directory so that the API can locate the kaggle.json credentials file. It then executes a shell command to change the file's permissions (chmod 600 kaggle.json), ensuring that only the owner can read and write it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "chmod: cannot access 'kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "! chmod 600 kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/home/cistudent/.local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/home/cistudent/.local/lib/python3.12/site-packages/kaggle/api/kaggle_api_extended.py\", line 164, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /workspaces/property-value-maximizer. Or use the environment method.\n"
          ]
        }
      ],
      "source": [
        "KaggleDatasetPath = \"codeinstitute/housing-prices-data\"\n",
        "DestinationFolder = \"inputs/datasets/raw\"   \n",
        "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open inputs/datasets/raw/*.zip, inputs/datasets/raw/*.zip.zip or inputs/datasets/raw/*.zip.ZIP.\n",
            "\n",
            "No zipfiles found.\n"
          ]
        }
      ],
      "source": [
        "! unzip {DestinationFolder}/*.zip -d {DestinationFolder} \\\n",
        "  && rm {DestinationFolder}/*.zip \\\n",
        "  && rm kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Uses pandas library to load two datasets into DataFrames from CSV files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(f\"inputs/datasets/raw/house-price-20211124T154130Z-001/house-price/house_prices_records.csv\")\n",
        "df_inherited = pd.read_csv(f\"inputs/datasets/raw/house-price-20211124T154130Z-001/house-price/inherited_houses.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Provides a concise summary of the df DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1460 entries, 0 to 1459\n",
            "Data columns (total 24 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   1stFlrSF       1460 non-null   int64  \n",
            " 1   2ndFlrSF       1374 non-null   float64\n",
            " 2   BedroomAbvGr   1361 non-null   float64\n",
            " 3   BsmtExposure   1422 non-null   object \n",
            " 4   BsmtFinSF1     1460 non-null   int64  \n",
            " 5   BsmtFinType1   1315 non-null   object \n",
            " 6   BsmtUnfSF      1460 non-null   int64  \n",
            " 7   EnclosedPorch  136 non-null    float64\n",
            " 8   GarageArea     1460 non-null   int64  \n",
            " 9   GarageFinish   1225 non-null   object \n",
            " 10  GarageYrBlt    1379 non-null   float64\n",
            " 11  GrLivArea      1460 non-null   int64  \n",
            " 12  KitchenQual    1460 non-null   object \n",
            " 13  LotArea        1460 non-null   int64  \n",
            " 14  LotFrontage    1201 non-null   float64\n",
            " 15  MasVnrArea     1452 non-null   float64\n",
            " 16  OpenPorchSF    1460 non-null   int64  \n",
            " 17  OverallCond    1460 non-null   int64  \n",
            " 18  OverallQual    1460 non-null   int64  \n",
            " 19  TotalBsmtSF    1460 non-null   int64  \n",
            " 20  WoodDeckSF     155 non-null    float64\n",
            " 21  YearBuilt      1460 non-null   int64  \n",
            " 22  YearRemodAdd   1460 non-null   int64  \n",
            " 23  SalePrice      1460 non-null   int64  \n",
            "dtypes: float64(7), int64(13), object(4)\n",
            "memory usage: 273.9+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Count the number of missing (null/NaN) values in each column of the df DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1stFlrSF            0\n",
              "2ndFlrSF           86\n",
              "BedroomAbvGr       99\n",
              "BsmtExposure       38\n",
              "BsmtFinSF1          0\n",
              "BsmtFinType1      145\n",
              "BsmtUnfSF           0\n",
              "EnclosedPorch    1324\n",
              "GarageArea          0\n",
              "GarageFinish      235\n",
              "GarageYrBlt        81\n",
              "GrLivArea           0\n",
              "KitchenQual         0\n",
              "LotArea             0\n",
              "LotFrontage       259\n",
              "MasVnrArea          8\n",
              "OpenPorchSF         0\n",
              "OverallCond         0\n",
              "OverallQual         0\n",
              "TotalBsmtSF         0\n",
              "WoodDeckSF       1305\n",
              "YearBuilt           0\n",
              "YearRemodAdd        0\n",
              "SalePrice           0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filter df, keeping only the rows that are duplicates. There are no duplicates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>...</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>0 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [1stFlrSF, 2ndFlrSF, BedroomAbvGr, BsmtExposure, BsmtFinSF1, BsmtFinType1, BsmtUnfSF, EnclosedPorch, GarageArea, GarageFinish, GarageYrBlt, GrLivArea, KitchenQual, LotArea, LotFrontage, MasVnrArea, OpenPorchSF, OverallCond, OverallQual, TotalBsmtSF, WoodDeckSF, YearBuilt, YearRemodAdd, SalePrice]\n",
              "Index: []\n",
              "\n",
              "[0 rows x 24 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df.duplicated(subset=None)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Provides a concise summary of the df_inherited DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4 entries, 0 to 3\n",
            "Data columns (total 23 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   1stFlrSF       4 non-null      int64  \n",
            " 1   2ndFlrSF       4 non-null      int64  \n",
            " 2   BedroomAbvGr   4 non-null      int64  \n",
            " 3   BsmtExposure   4 non-null      object \n",
            " 4   BsmtFinSF1     4 non-null      float64\n",
            " 5   BsmtFinType1   4 non-null      object \n",
            " 6   BsmtUnfSF      4 non-null      float64\n",
            " 7   EnclosedPorch  4 non-null      int64  \n",
            " 8   GarageArea     4 non-null      float64\n",
            " 9   GarageFinish   4 non-null      object \n",
            " 10  GarageYrBlt    4 non-null      float64\n",
            " 11  GrLivArea      4 non-null      int64  \n",
            " 12  KitchenQual    4 non-null      object \n",
            " 13  LotArea        4 non-null      int64  \n",
            " 14  LotFrontage    4 non-null      float64\n",
            " 15  MasVnrArea     4 non-null      float64\n",
            " 16  OpenPorchSF    4 non-null      int64  \n",
            " 17  OverallCond    4 non-null      int64  \n",
            " 18  OverallQual    4 non-null      int64  \n",
            " 19  TotalBsmtSF    4 non-null      float64\n",
            " 20  WoodDeckSF     4 non-null      int64  \n",
            " 21  YearBuilt      4 non-null      int64  \n",
            " 22  YearRemodAdd   4 non-null      int64  \n",
            "dtypes: float64(7), int64(12), object(4)\n",
            "memory usage: 868.0+ bytes\n"
          ]
        }
      ],
      "source": [
        "df_inherited.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Count the number of missing (null/NaN) values in each column of the df_inherited DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1stFlrSF         0\n",
              "2ndFlrSF         0\n",
              "BedroomAbvGr     0\n",
              "BsmtExposure     0\n",
              "BsmtFinSF1       0\n",
              "BsmtFinType1     0\n",
              "BsmtUnfSF        0\n",
              "EnclosedPorch    0\n",
              "GarageArea       0\n",
              "GarageFinish     0\n",
              "GarageYrBlt      0\n",
              "GrLivArea        0\n",
              "KitchenQual      0\n",
              "LotArea          0\n",
              "LotFrontage      0\n",
              "MasVnrArea       0\n",
              "OpenPorchSF      0\n",
              "OverallCond      0\n",
              "OverallQual      0\n",
              "TotalBsmtSF      0\n",
              "WoodDeckSF       0\n",
              "YearBuilt        0\n",
              "YearRemodAdd     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_inherited.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filter df_inherited, keeping only the rows that are duplicates. There are no duplicates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>...</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>0 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [1stFlrSF, 2ndFlrSF, BedroomAbvGr, BsmtExposure, BsmtFinSF1, BsmtFinType1, BsmtUnfSF, EnclosedPorch, GarageArea, GarageFinish, GarageYrBlt, GrLivArea, KitchenQual, LotArea, LotFrontage, MasVnrArea, OpenPorchSF, OverallCond, OverallQual, TotalBsmtSF, WoodDeckSF, YearBuilt, YearRemodAdd]\n",
              "Index: []\n",
              "\n",
              "[0 rows x 23 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_inherited[df_inherited.duplicated(subset=None)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Iterate over the columns of the DataFrame df and performs checks on the unique values in each column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BedroomAbvGr - 9\n",
            "BsmtExposure - ['No' 'Gd' 'Mn' 'Av' nan]\n",
            "BsmtFinType1 - ['GLQ' 'ALQ' 'Unf' 'Rec' nan 'BLQ' 'LwQ']\n",
            "GarageFinish - ['RFn' 'Unf' nan 'Fin']\n",
            "KitchenQual - ['Gd' 'TA' 'Ex' 'Fa']\n",
            "OverallCond - 9\n",
            "OverallQual - 10\n"
          ]
        }
      ],
      "source": [
        "for col in df.columns:\n",
        "    unique_values = df[col].unique()\n",
        "    \n",
        "    if df[col].dtype == 'object':\n",
        "        print(f\"{col} - {unique_values}\")\n",
        "    elif len(unique_values) < 11:\n",
        "        print(f\"{col} - {len(unique_values)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a directory structure and then save the two dataframes as CSV files to outputs/datasets/collection/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 17] File exists: 'outputs/datasets/collection'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "try:\n",
        "  os.makedirs(name='outputs/datasets/collection')\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n",
        "df.to_csv(f\"outputs/datasets/collection/HousePricesRecords.csv\",index=False)\n",
        "df_inherited.to_csv(f\"outputs/datasets/collection/InheritedHouses.csv\",index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusions and Next Steps\n",
        "\n",
        "The dataset contains 1460 rows and 24 columns.\n",
        "The data types present include integers, floats, and objects.\n",
        "There are no duplicate rows in the dataset.\n",
        "10 columns have missing values, with some columns having almost all of their entries missing.\n",
        "The columns BsmtExposure, BsmtFinType1, GarageFinish, KitchenQual consist of categorical variables.\n",
        "Data cleaning and preprocessing are necessary to address the missing values and to properly handle the categorical variables in certain columns.\n",
        "\n",
        "The Next Steps are to check for missing values in the dataset, address missing values in the dataset, and implement the data cleaning process."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
