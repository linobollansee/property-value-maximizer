{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **01 - DataCollection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Fetch data from Kaggle and store it as raw data in inputs/datasets/raw\n",
        "* Inspect data fetched via Kaggle\n",
        "* Save data fetched under outputs/datasets/collection/\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* My personal Kaggle JSON file to authenticate with Kaggle \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* inputs/datasets/raw/house-price-20211124T154130Z-001/house-price/house_prices_records.csv\n",
        "* inputs/datasets/raw/house-price-20211124T154130Z-001/house-price/inherited_houses.csv\n",
        "* inputs/datasets/raw/house-metadata.txt\n",
        "* outputs/datasets/collection/HousePricesRecords.csv\n",
        "* outputs/datasets/collection/InheritedHouses.csv\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* The file inherited_houses.csv contains features and target variables for the business objective, serving as the foundation for the ML model. It also includes house features for which the client seeks individual and total price predictions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Download data from Kaggle\n",
        "\n",
        "The Kaggle API was used to fetch the raw project data, requiring the installation of the Kaggle package.\n",
        "\n",
        "To authenticate, the API requires a token stored in a kaggle.json file. The token was obtained as follows:\n",
        "\n",
        "Log into your Kaggle account.\n",
        "Go to Settings via the user profile menu.\n",
        "Locate the API section.\n",
        "Click Expire API Token to remove any existing tokens.\n",
        "Click Create New API Token to generate a new one.\n",
        "Download the kaggle.json file.\n",
        "Move kaggle.json to the project's root directory without renaming or changing its extension.\n",
        "This ensures proper authentication for accessing Kaggle data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install kaggle==1.5.12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This code configures Kaggle API authentication by setting the KAGGLE_CONFIG_DIR environment variable to the current working directory so that the API can locate the kaggle.json credentials file. It then executes a shell command to change the file's permissions (chmod 600 kaggle.json), ensuring that only the owner can read and write it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "! chmod 600 kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "KaggleDatasetPath = \"codeinstitute/housing-prices-data\"\n",
        "DestinationFolder = \"inputs/datasets/raw\"   \n",
        "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! unzip {DestinationFolder}/*.zip -d {DestinationFolder} \\\n",
        "  && rm {DestinationFolder}/*.zip \\\n",
        "  && rm kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Uses pandas library to load two datasets into DataFrames from CSV files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(f\"inputs/datasets/raw/house-price-20211124T154130Z-001/house-price/house_prices_records.csv\")\n",
        "df_inherited = pd.read_csv(f\"inputs/datasets/raw/house-price-20211124T154130Z-001/house-price/inherited_houses.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Provides a concise summary of the df DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Count the number of missing (null/NaN) values in each column of the df DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filter df, keeping only the rows that are duplicates. There are no duplicates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[df.duplicated(subset=None)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Provides a concise summary of the df_inherited DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_inherited.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Count the number of missing (null/NaN) values in each column of the df_inherited DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_inherited.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filter df_inherited, keeping only the rows that are duplicates. There are no duplicates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_inherited[df_inherited.duplicated(subset=None)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Iterate over the columns of the DataFrame df and performs checks on the unique values in each column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for col in df.columns:\n",
        "    unique_values = df[col].unique()\n",
        "    \n",
        "    if df[col].dtype == 'object':\n",
        "        print(f\"{col} - {unique_values}\")\n",
        "    elif len(unique_values) < 11:\n",
        "        print(f\"{col} - {len(unique_values)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a directory structure and then save the two dataframes as CSV files to outputs/datasets/collection/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  os.makedirs(name='outputs/datasets/collection')\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n",
        "df.to_csv(f\"outputs/datasets/collection/HousePricesRecords.csv\",index=False)\n",
        "df_inherited.to_csv(f\"outputs/datasets/collection/InheritedHouses.csv\",index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusions and Next Steps\n",
        "\n",
        "The dataset contains 1460 rows and 24 columns.\n",
        "The data types present include integers, floats, and objects.\n",
        "There are no duplicate rows in the dataset.\n",
        "10 columns have missing values, with some columns having almost all of their entries missing.\n",
        "The columns BsmtExposure, BsmtFinType1, GarageFinish, KitchenQual consist of categorical variables.\n",
        "Data cleaning and preprocessing are necessary to address the missing values and to properly handle the categorical variables in certain columns.\n",
        "\n",
        "The Next Steps are to check for missing values in the dataset, address missing values in the dataset, and implement the data cleaning process."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
