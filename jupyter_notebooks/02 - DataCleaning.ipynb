{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **02 - DataCleaning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Check for missing values in the dataset\n",
        "* Address missing values in the dataset\n",
        "* Data cleaning process\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/HousePricesRecords.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* outputs/datasets/cleaned/train_set_cleaned.csv\n",
        "* outputs/datasets/cleaned/test_set_cleaned.csv\n",
        "* outputs/datasets/cleaned/HousePricesCleaned.csv\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Uses pandas library to load dataset into DataFrames df and displays the first 10 rows of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"outputs/datasets/collection/HousePricesRecords.csv\")\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Identifies and extracts the names of columns in the DataFrame df that contain missing (NaN) values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "columns_with_missing_values = df.columns[df.isna().sum() > 0].to_list()\n",
        "columns_with_missing_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Returns the number of elements in the columns_with_missing_values list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(columns_with_missing_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Summary only for the columns in columns_with_missing_values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[columns_with_missing_values].info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If columns_with_missing_values exist, generate a minimal data profile report using the ydata_profiling library. If no columns with missing data are found, print a message indicating there are no columns with missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "if columns_with_missing_values:\n",
        "    profile = ProfileReport(df=df[columns_with_missing_values], minimal=True)\n",
        "    profile.to_notebook_iframe()\n",
        "else:\n",
        "    print(\"There are no columns with missing data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analyzes missing data in a DataFrame by calculating the number of missing values and the percentage of missing data for each column. Creates a new DataFrame containing the count of missing values, the percentage of missing data, and the data type for each column. This new DataFrame is sorted by the percentage of missing data in descending order and filtered to include only columns with missing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def EvaluateMissingData(df):\n",
        "    missing_data_absolute = df.isnull().sum()\n",
        "    missing_data_percentage = round(missing_data_absolute/len(df)*100, 2)\n",
        "    df_missing_data = (pd.DataFrame(\n",
        "                            data={\"RowsWithMissingData\": missing_data_absolute,\n",
        "                                   \"PercentageOfDataset\": missing_data_percentage,\n",
        "                                   \"DataType\": df.dtypes}\n",
        "                                    )\n",
        "                          .sort_values(by=['PercentageOfDataset'], ascending=False)\n",
        "                          .query(\"PercentageOfDataset > 0\")\n",
        "                          )\n",
        "\n",
        "    return df_missing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EvaluateMissingData(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualizes the impact of data cleaning by comparing the distribution of specified variables in original and cleaned datasets. It generates bar plots for categorical variables and histograms for numerical ones, to assess the effect of data cleaning visually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "def DataCleaningEffect(df_original, df_cleaned, variables_applied_with_method):\n",
        "    \"\"\"\n",
        "    Function to visualize data cleaning effect\n",
        "    \"\"\"\n",
        "    flag_count = 1\n",
        "\n",
        "    # Identify categorical variables\n",
        "    categorical_variables = df_original.select_dtypes(exclude=['number']).columns\n",
        "\n",
        "    # Loop through each variable in the list provided\n",
        "    for var in variables_applied_with_method:\n",
        "        print(\"\\n=====================================================================================\")\n",
        "        print(f\"* Distribution Effect Analysis After Data Cleaning Method on variable: {var}\")\n",
        "\n",
        "        if var in categorical_variables:\n",
        "            # For categorical variables, create a bar plot\n",
        "            df1 = pd.DataFrame({\"Type\": \"Original\", \"Value\": df_original[var]})\n",
        "            df2 = pd.DataFrame({\"Type\": \"Cleaned\", \"Value\": df_cleaned[var]})\n",
        "            dfAux = pd.concat([df1, df2], axis=0)\n",
        "            dfAux.reset_index(drop=True, inplace=True)  # Reset the index to avoid duplicates\n",
        "\n",
        "            fig, axes = plt.subplots(figsize=(15, 5))\n",
        "            sns.countplot(data=dfAux, x=\"Value\", hue=\"Type\", palette=['#432371', \"#FAAE7B\"])\n",
        "            axes.set_title(f\"Distribution Plot {flag_count}: {var}\")\n",
        "            plt.xticks(rotation=90)\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "            print(f\"Displaying bar plot for categorical variable: {var}\")\n",
        "\n",
        "        else:\n",
        "            # For numerical variables, create histograms\n",
        "            fig, axes = plt.subplots(figsize=(10, 5))\n",
        "            sns.histplot(data=df_original, x=var, color=\"#432371\", label='Original', kde=True, element=\"step\", ax=axes)\n",
        "            sns.histplot(data=df_cleaned, x=var, color=\"#FAAE7B\", label='Cleaned', kde=True, element=\"step\", ax=axes)\n",
        "            axes.set_title(f\"Distribution Plot {flag_count}: {var}\")\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "            print(f\"Displaying histogram for numerical variable: {var}\")\n",
        "\n",
        "        plt.close(fig)\n",
        "        flag_count += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Splits a DataFrame into training and testing sets for machine learning purposes, where TrainSet contains 80% of the data and TestSet contains 20%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "TrainSet, TestSet, _, __ = train_test_split(\n",
        "                                        df,\n",
        "                                        df['SalePrice'],\n",
        "                                        test_size=0.2,\n",
        "                                        random_state=0)\n",
        "\n",
        "print(f\"TrainSet shape: {TrainSet.shape} \\nTestSet shape: {TestSet.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluates and prints information about missing data in the TrainSet DataFrame. The number of variables with missing data is printed, followed by the details of these variables. Additionally, it prints the names of all columns present in the TrainSet DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_missing_data = EvaluateMissingData(TrainSet)\n",
        "print(f\"* There are {df_missing_data.shape[0]} variables with missing data \\n\")\n",
        "print(df_missing_data)\n",
        "\n",
        "print(f\"TrainSet columns: {TrainSet.columns}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Remove columns EnclosedPorch and WoodDeckSF, from the TrainSet DataFrame. They both have an extreme amount of missing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.selection import DropFeatures\n",
        "\n",
        "variables_to_drop=['EnclosedPorch' , 'WoodDeckSF']\n",
        "imputer = DropFeatures(features_to_drop=variables_to_drop)\n",
        "df_method = imputer.fit_transform(TrainSet)\n",
        "\n",
        "for i in variables_to_drop:\n",
        "    print(i in df_method.columns.to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "3.12.1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
